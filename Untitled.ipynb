{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6038f44c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "Type 2    386\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Question 1\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the provided URL\n",
    "url = 'https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv'\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Check for missing values in the dataset\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "# Display columns with missing values\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values[missing_values > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a5abf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 800 rows and 12 columns.\n"
     ]
    }
   ],
   "source": [
    "#Question 2\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = 'https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv'\n",
    "pokemon_data = pd.read_csv(url)\n",
    "\n",
    "# Get the number of rows and columns\n",
    "rows, columns = pokemon_data.shape\n",
    "\n",
    "# Output the results\n",
    "print(f\"The dataset has {rows} rows and {columns} columns.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb804895",
   "metadata": {},
   "source": [
    "Observations: Each Pokémon entry (each row) in the dataset.(DEFINITION)Observations refer to individual data points or records in each row. Each row in a dataset represents a observation. \n",
    "Variables: The different attributes describing each Pokémon, such as Name, Type 1, HP, Attack, etc.(DEFINITION) Variables are the different attributes that are recorded for each observation.Each column in a dataset represents a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "155e2ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   #           800 non-null    int64 \n",
      " 1   Name        800 non-null    object\n",
      " 2   Type 1      800 non-null    object\n",
      " 3   Type 2      414 non-null    object\n",
      " 4   HP          800 non-null    int64 \n",
      " 5   Attack      800 non-null    int64 \n",
      " 6   Defense     800 non-null    int64 \n",
      " 7   Sp. Atk     800 non-null    int64 \n",
      " 8   Sp. Def     800 non-null    int64 \n",
      " 9   Speed       800 non-null    int64 \n",
      " 10  Generation  800 non-null    int64 \n",
      " 11  Legendary   800 non-null    bool  \n",
      "dtypes: bool(1), int64(8), object(3)\n",
      "memory usage: 69.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 3\n",
    "pokemon_data.info()\n",
    "pokemon_data.describe()\n",
    "pokemon_data['Type 1'].value_counts()\n",
    "pokemon_data.isnull().sum()\n",
    "pokemon_data['Type 1'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "990d892e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 15)\n",
      "         survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n"
     ]
    }
   ],
   "source": [
    "#QUESTION 4\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Check shape\n",
    "print(df.shape)\n",
    "\n",
    "# Describe numeric columns\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4dfd63",
   "metadata": {},
   "source": [
    "df.shape reports the total number of columns (numeric + non-numeric).\n",
    "df.describe() (without any extra arguments) only analyzes the numeric columns.\n",
    "The \"count\" column in df.describe() shows how many non-missing (non-NaN) values exist for each numeric column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24db0b8",
   "metadata": {},
   "source": [
    "QUESTION 5:an \"attribute\" :An attribute is the property of an object and it can store data or information about the object. They do not require parentheses because they don't perform any action—they simply return the stored information.\n",
    "a \"method\":A method is a function that is associated with an object and performs an action.Even if no arguments are needed, the parentheses are still required to \"call\" the method and execute the underlying code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeabf4af",
   "metadata": {},
   "source": [
    "QUESTION 6 \n",
    "1.Count:\n",
    "The number of non-missing values for each variable.If a column contains missing values (e.g., NaN), these are excluded from the count.\n",
    "2.Mean:\n",
    "The average value of the variable, calculated by summing all non-missing values and dividing by the count.\n",
    "3.Standard Deviation (std):\n",
    "A measure of the spread or dispersion of the data. It indicates how much the values differ from the mean.\n",
    "4.Minimum (min):\n",
    "The smallest value in the variable.\n",
    "5.25% (First Quartile / Q1):\n",
    "The value below which 25% of the data falls.It is the first quartile, which is the median of the lower half of the data.This value helps describe the lower boundary of the central 50% of the data.\n",
    "6.50% (Median or Second Quartile / Q2):\n",
    "The median, or the value at the midpoint of the data.50% of the data points are below this value and 50% are above it.It is less sensitive to outliers than the mean.\n",
    "7.75% (Third Quartile / Q3):\n",
    "The value below which 75% of the data falls.It is the third quartile, which represents the upper boundary of the central 50% of the data.This value helps describe the upper part of the distribution.\n",
    "8.Maximum (max):\n",
    "Definition: The largest value in the variable.\n",
    "It represents the highest data point in the distribution of values.\n",
    "\n",
    " \n",
    "Explanation Regarding Missing Data\n",
    "When df.describe() is used, missing data (NaN) is ignored in the summary statistics. Only the non-missing values are considered. Here's how missing data is handled for each statistic:\n",
    "\n",
    "Count reflects the number of non-missing values in each column.\n",
    "Mean, std, min, 25%, 50%, 75%, and max are calculated based only on the non-missing values.\n",
    "Thus, missing values do not affect the actual calculation of these statistics, but the count is important to note since it shows how many valid values were used in the computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04ab381",
   "metadata": {},
   "source": [
    "link of chatbot:https://chatgpt.com/share/02a8b6ca-8ace-4b27-aacc-3f818f5a9b2b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca581152",
   "metadata": {},
   "source": [
    "Question 7 \n",
    "(1)Use Case 1: When df.dropna() is preferred over del df['col']\n",
    " df.dropna() is preferred to remove rows to preserve as many columns as possible.When the missing data is dispersed over a few rows and columns and I wish to preserve most of the dataset's structure, I would use df.dropna().\n",
    "Example:In the Titanic dataset, I would use df.dropna() to delete the incomplete rows if there are only a few rows with missing values in the 'age', 'embarked', or 'fare' columns and those variables are crucial for analysis.This allows me to retain the relevant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6f9bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values, keeping all columns\n",
    "cleaned_df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3eca9d",
   "metadata": {},
   "source": [
    " Question 7 \n",
    "(2)Use Case 2: When del df['col'] is preferred over df.dropna()\n",
    "I would prefer del df['col'] when a specific column has a significant number of missing values, making it unusable for analysis or an entire column has too many missing values. del df['col' ]helps when a specific column is not necessary for the analysis.Removing the entire column is more efficient because it prevents the loss of rows that may otherwise be complete.\n",
    "Example:\n",
    "In the Titanic dataset, the 'Cabin' or 'deck' columns often have a large number of missing values. Using del df['deck'] would be more efficient than df.dropna() because removing the column preserves rows that have complete data in other relevant columns.This method is preferred when the goal is to preserve most of the columns in the dataset, especially when missing data is isolated to only a few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776cdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the entire column 'Type 2'\n",
    "del df['Cabin']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe58e2f8",
   "metadata": {},
   "source": [
    "Question 7 (3)\n",
    "Applying del df['col'] before df.dropna() is important in order to avoid losing rows that contain vital data in other columns. Many rows may be discarded when using df.dropna() if a column has a high percentage of missing values. This is true even if the rows may include complete data in other significant columns.When both del df['col'] and df.dropna() are used together, the order of application can significantly affect how much data is retained and the quality of the dataset. \n",
    "Deleting a column with missing data before applying df.dropna() ensures that rows with missing values in that column are not unnecessary removed. If you apply df.dropna() first, rows with missing values in that column would be deleted, even if other columns were complete. This could lead to the unnecessary loss of valuable data across other columns.\n",
    "Deleting irrelevant or mostly empty columns first reduces the likelihood that df.dropna() will over-remove rows due to missing values in those columns. This allows df.dropna() to focus on removing rows with missing values in columns that are more important to your analysis.\n",
    "For example,In the Titanic dataset , the 'deck' column has a high number of missing values. If I apply df.dropna() without first removing 'deck' column, a large number of rows will be dropped due to the missing values in the column, even though the remaining columns (like 'age' or 'fare') might have complete data.If I first using del df['deck']:I can remove the column with excessive missing values first. Then I apply df.dropna(), only rows with missing values in critical columns (such as 'age', 'embarked', etc.) are removed, preserving most of the useful data.\n",
    "Applying del df['col'] before df.dropna() helps preserve as many complete rows as possible, ensuring that the dataset remains rich in non-missing data while irrelevant or problematic columns are removed early on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1ab3cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before cleaning:\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Question 7 (4)  Count missing values per column before cleaning\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Count missing values per column before cleaning\n",
    "missing_before = df.isnull().sum()\n",
    "\n",
    "# Display the missing values count\n",
    "print(\"Missing values before cleaning:\")\n",
    "print(missing_before)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56b498d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived       0\n",
       "pclass         0\n",
       "sex            0\n",
       "age            0\n",
       "sibsp          0\n",
       "parch          0\n",
       "fare           0\n",
       "embarked       0\n",
       "class          0\n",
       "who            0\n",
       "adult_male     0\n",
       "embark_town    0\n",
       "alive          0\n",
       "alone          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete the 'deck' column\n",
    "del df['deck']\n",
    "\n",
    "# Drop rows with remaining missing values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Count missing values per column after cleaning\n",
    "missing_after = df_cleaned.isnull().sum()\n",
    "missing_after\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0049c909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 712 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   survived     712 non-null    int64  \n",
      " 1   pclass       712 non-null    int64  \n",
      " 2   sex          712 non-null    object \n",
      " 3   age          712 non-null    float64\n",
      " 4   sibsp        712 non-null    int64  \n",
      " 5   parch        712 non-null    int64  \n",
      " 6   fare         712 non-null    float64\n",
      " 7   embarked     712 non-null    object \n",
      " 8   class        712 non-null    object \n",
      " 9   who          712 non-null    object \n",
      " 10  adult_male   712 non-null    bool   \n",
      " 11  embark_town  712 non-null    object \n",
      " 12  alive        712 non-null    object \n",
      " 13  alone        712 non-null    bool   \n",
      "dtypes: bool(2), float64(2), int64(4), object(6)\n",
      "memory usage: 73.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#Count missing values per column after cleaning\n",
    "df_cleaned.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd843b85",
   "metadata": {},
   "source": [
    "Question 7.4 Approach:\n",
    "Removing columns with excessive missing data: If a column has too many missing values (for example, the deck column with 688 missing values), we will remove it entirely because it doesn't provide enough information to be useful,and we can use del df['col'] for columns to remove excessive missing data\n",
    "Removing rows with missing values: For other columns like age, embarked, and embark_town, we can choose to drop rows where the data is missing.So we can use df.dropna() to remove rows with any missing data.\n",
    "Justification:\n",
    "(Before cleaning)\n",
    "Deck:It is preferable to delete this column because it contains 688 missing values, too numerous for imputation or analysis.\n",
    "Age, Embarked, Embark_town: These columns have a smaller number of missing values (177 for age, 2 for embarked, 2 for embark_town). By dropping rows with missing values here, we ensure the dataset remains consistent.\n",
    "After cleaning process, we ensure that the final dataset contains no missing values and is more reliable for further analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff71e3b",
   "metadata": {},
   "source": [
    "chatbot:https://chatgpt.com/share/8c379c90-a5bb-417a-88a2-6557e9b964fa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6e479d",
   "metadata": {},
   "source": [
    "Question8.1\n",
    "df.groupby(\"col1\"): This groups the DataFrame df by the unique values in col1. For example, if col1 represents \"Survived\" (which has values 0 or 1), it will split the data into two groups: one for passengers who did not survive and one for those who did.\n",
    "\n",
    "[\"col2\"]: This selects the column col2 that you want to analyze. For instance, if col2 is \"Fare\", then you are grouping by \"Survived\" and analyzing the fares for each group.\n",
    "\n",
    ".describe(): This computes summary statistics for each group, such as the count, mean, standard deviation, minimum, 25th percentile, median (50th percentile), 75th percentile, and maximum. The result will give these statistics for each group formed by col1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cc0ef3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.42</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Third</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.67</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Second</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Third</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.83</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Second</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.92</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>First</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70.00</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Second</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70.50</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Third</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71.00</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>First</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74.00</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Third</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80.00</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>First</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      count unique     top freq\n",
       "age                            \n",
       "0.42      1      1   Third    1\n",
       "0.67      1      1  Second    1\n",
       "0.75      2      1   Third    2\n",
       "0.83      2      1  Second    2\n",
       "0.92      1      1   First    1\n",
       "...     ...    ...     ...  ...\n",
       "70.00     2      2  Second    1\n",
       "70.50     1      1   Third    1\n",
       "71.00     2      1   First    2\n",
       "74.00     1      1   Third    1\n",
       "80.00     1      1   First    1\n",
       "\n",
       "[88 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by 'age' and describe the 'class' column\n",
    "result = df.groupby(\"age\")[\"class\"].describe()\n",
    "\n",
    "# Display the result\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef6451a",
   "metadata": {},
   "source": [
    "Question8.2\n",
    "Key Differences:\n",
    "In df.describe(): The count represents the number of valid (non-missing) values for each column across the entire dataset.Each column may have a different count since missing values (NaNs) are handled separately,so columns that have missing values will have a lower count.It shows a global summary of each column's values across the entire dataset.\n",
    "In df.groupby(\"col1\")[\"col2\"].describe(): The count represents the number of valid (non-missing) values for col2 within each group defined by col1. It can break down the data based on unique categories in col1 and showing how the statistics (including the count) vary across those categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91cf2bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         survived      pclass         age       sibsp       parch        fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# General summary statistics for all columns\n",
    "summary = df.describe()\n",
    "\n",
    "# Display the result\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d8b23fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186.0</td>\n",
       "      <td>38.233441</td>\n",
       "      <td>14.802856</td>\n",
       "      <td>0.92</td>\n",
       "      <td>27.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173.0</td>\n",
       "      <td>29.877630</td>\n",
       "      <td>14.001077</td>\n",
       "      <td>0.67</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>355.0</td>\n",
       "      <td>25.140620</td>\n",
       "      <td>12.495398</td>\n",
       "      <td>0.42</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std   min   25%   50%   75%   max\n",
       "pclass                                                           \n",
       "1       186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0\n",
       "2       173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0\n",
       "3       355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by 'Pclass' and describe the 'Age' column\n",
    "grouped_summary = df.groupby(\"pclass\")[\"age\"].describe()\n",
    "\n",
    "# Display the result\n",
    "grouped_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d52c1b",
   "metadata": {},
   "source": [
    "#Question 8.3\n",
    "a.Chatbot:The error \"NameError: name 'pd' is not defined\" occurs because the pandas library (which is typically aliased as pd) has not been imported in the current Python session. To fix this, you need to import the pandas library before using it.\n",
    "You can solve this error by adding the following line at the beginning of your script or notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f323602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# General summary statistics for all columns\n",
    "summary = df.describe()\n",
    "\n",
    "# Display the result\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849771a0",
   "metadata": {},
   "source": [
    "Google:I search for the error message \"NameError: name 'pd' is not defined\" on Google.Results:\n",
    "The search results would likely point to common forum discussions (e.g., Stack Overflow) where users suggest including the import pandas as pd statement.\n",
    "After browsing the results, I would find the solution to add the missing import statement.\n",
    "MY OPINION:Working in a chatbot session (option (a)) appears to be faster and more efficient than searching on Google. ChatGPT instantly detects the core reason and provides an instantaneous solution, eliminating the need for extensive searches or sorting through search results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd474ed6",
   "metadata": {},
   "source": [
    "#Question 8.3 b\n",
    "chatbot:This indicates that Python tried to find a file with the incorrect name but couldn't locate it. Make sure the filename and path are correct when loading data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd6dce4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Correct filename: 'titanic.csv'\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the dataframe to verify it's loaded correctly\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1837a9f",
   "metadata": {},
   "source": [
    "Google:Searching for FileNotFoundError: [Errno 2] No such file or directory on Google would point me to similar issues where the file path or name is incorrect. While this is helpful, I'd still need to check the URL to find the mistake manually.\n",
    "MY OPINION:ChatGPT provides immediate feedback with targeted suggestions, helping me focus on where the error might be while Google search results may help with understanding the types of errors (e.g., 404, URLError), it requires more effort on the user's part to identify the exact issue within the URL.And the search results provide broader explanations, which might require users to sift through irrelevant information before finding a solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be63d3b",
   "metadata": {},
   "source": [
    "#Question 8.3 c\n",
    "chatbot:\n",
    "The error \"NameError: name 'DF' is not defined\" occurs because DF has not been defined. In Python, names are case-sensitive, so if you intended to use a DataFrame named df but mistakenly typed DF, Python won't recognize it.\n",
    "\n",
    "To solve this, ensure you're using the correct name for your DataFrame, which is usually lowercase df if you defined it that way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d09cb219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n"
     ]
    }
   ],
   "source": [
    "#Correct Example:\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Use the correct lowercase 'df' when referring to your DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b59dff",
   "metadata": {},
   "source": [
    "Google:I searched for NameError: name 'DF' is not defined.A Google search points me to explanations of Python's NameError and cases where the variable has not been defined. The results would help me understand that I either need to define the variable DF or correct the variable name if it's a typo.\n",
    "MY Opinion:Chatbot is more convinent and faster while google is time-consuming,and Google search results can provide a deeper explanation of what NameError is and various scenarios where it can occur, but this generality might not be as efficient for fixing this specific issue quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c41bac",
   "metadata": {},
   "source": [
    "#Question 8.3 d\n",
    "chatbot:The SyntaxError: incomplete input error occurs when Python encounters a line of code that is not complete or properly closed. In this case, it seems like there is a missing closing parenthesis or other syntax issue.\n",
    "Common Causes of This Error:\n",
    "Missing Parentheses: Ensure that every opening parenthesis ( has a corresponding closing parenthesis ). For example, pd.read_csv(url is incomplete because it is missing a closing parenthesis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab04352b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n"
     ]
    }
   ],
   "source": [
    "#Corrected Code:\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URL for the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "\n",
    "# Read the dataset from the URL\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the dataframe to ensure it loaded correctly\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8604b9b9",
   "metadata": {},
   "source": [
    "Google:I searched SyntaxError: incomplete input.A Google search shows various discussions about this syntax error, with explanations indicating that it’s often caused by incomplete or incorrect syntax, including missing parentheses.\n",
    "MY OPINION:ChatGPT gives direct solution and useful help while Google search provides a range of explanations and solutions for syntax errors, which may include examples of missing parentheses.Google search may waste time if I want to get the solution directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68bd6e7",
   "metadata": {},
   "source": [
    "#Question 8.3 e\n",
    "chatbot tells me:this will raise an AttributeError because DataFrame objects in pandas do not have a group_by method. The correct method is groupby.I should use groupby, not group_by and ensure method names are spelled correctly, e.g., describe, not describle.To properly use groupby and describe, ensure the correct method names and spelling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95ea67aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count       mean        std   min   25%   50%   75%   max\n",
      "pclass                                                           \n",
      "1       186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0\n",
      "2       173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0\n",
      "3       355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Correct usage of groupby and describe\n",
    "grouped_summary = df.groupby(\"pclass\")[\"age\"].describe()\n",
    "\n",
    "# Display the result\n",
    "print(grouped_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144cb4c7",
   "metadata": {},
   "source": [
    "Google:For group_by Error:\n",
    "Searching for AttributeError: 'DataFrame' object has no attribute 'group_by'.Google search results would likely discuss AttributeError and suggest checking method names. However, it might require reviewing various forums or documentation to understand that group_by should be groupby.\n",
    "For describle Error,it's similar.\n",
    "MY OPINION:Chatbot has immediate recognition ,which can quickly identify that the error is due to a typo in the method names and suggest the correct methods.It can provide direct guidance: offers targeted advice based on the specific errors, making it easier to fix the issue promptly. Google search has broader context,it provides more general information about AttributeError and might help in understanding the error in a broader context. However, identifying the exact typo might take more time and involve more effort to sift through search results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1060fa8f",
   "metadata": {},
   "source": [
    "#Question 8.3 f\n",
    "chatbot:I described the error KeyError: 'Sex'.ChatGPT would recognize that this error is due to a mismatch in column names. It would suggest checking the column names in the DataFrame to ensure they are used correctly.I should check column names and verify column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7d6fe4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
      "       'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',\n",
      "       'alive', 'alone'],\n",
      "      dtype='object')\n",
      "        count       mean        std   min   25%   50%   75%   max\n",
      "sex                                                              \n",
      "female  261.0  27.915709  14.110146  0.75  18.0  27.0  37.0  63.0\n",
      "male    453.0  30.726645  14.678201  0.42  21.0  29.0  39.0  80.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Check column names\n",
    "print(df.columns)\n",
    "\n",
    "# Group by 'Sex' and describe 'Age'\n",
    "grouped_summary = df.groupby(\"sex\")[\"age\"].describe()\n",
    "\n",
    "# Display the result\n",
    "print(grouped_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641d02e0",
   "metadata": {},
   "source": [
    "Google search results would explain that a KeyError indicates that the column does not exist. Various results would suggest checking for column name typos or verifying the DataFrame's columns.\n",
    "MY OPINION:For identifying issues with non-existent column names, ChatGPT offers a quicker and more focused solution by directly recognizing the column name mismatch and suggesting the correct names. Google search provides useful information but may involve more effort to pinpoint the exact issue, especially for specific column name errors.It takes time to search through results and documentation to find specific guidance related to column names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaa9bd3",
   "metadata": {},
   "source": [
    "#Question 8.3  g\n",
    "chatbot:It seems like the code snippet might be missing quotes around the column name sex. Column names should be passed as strings when referencing them in pandas methods. NameError: name 'age' is not defined is similar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03c7a17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        count       mean        std   min   25%   50%   75%   max\n",
      "sex                                                              \n",
      "female  261.0  27.915709  14.110146  0.75  18.0  27.0  37.0  63.0\n",
      "male    453.0  30.726645  14.678201  0.42  21.0  29.0  39.0  80.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "titanic_df = pd.read_csv(url)\n",
    "\n",
    "# Group by 'sex' and describe the 'age' column\n",
    "grouped_summary = titanic_df.groupby(\"sex\")[\"age\"].describe()\n",
    "\n",
    "# Display the result\n",
    "print(grouped_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d301b3d9",
   "metadata": {},
   "source": [
    "Google:Google search results explains that a NameError indicates that a variable is not defined. It provides general troubleshooting advice for undefined variables,suggest checking if the variable should be defined or, in this case, if the column name should be in quotes. The issue may require manually determining that the column name should be a string.\n",
    "MY OPINION:For issues related to forgetting quotes around column names, ChatGPT offers specific guidance based on the error message and context of using column names in DataFrame operations. Google search provides useful information but may be less immediate and requires additional effort to pinpoint the exact solution related to column name quoting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61c471a",
   "metadata": {},
   "source": [
    "Chatbot:https://chatgpt.com/share/1dda11c6-8d59-4ec4-ab1b-f266bb50492b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378de69c",
   "metadata": {},
   "source": [
    "Question 9 Yes, I have eviewed the course wiki-textbook and interacted with a ChatBot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
